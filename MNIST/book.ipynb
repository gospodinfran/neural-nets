{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = datasets.MNIST(\"data\", train=True,  download=True, transform=ToTensor())\n",
    "test = datasets.MNIST(\"data\", train=False,  download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training, batch_size=64)\n",
    "test_dataloader = DataLoader(test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_train_dataloader = DataLoader(training, batch_size=64)\n",
    "cnn_test_dataloader = DataLoader(test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, label in cnn_train_dataloader:\n",
    "    images = images.view(-1, 1, 28, 28)\n",
    "for images, label in cnn_test_dataloader:\n",
    "    images = images.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 300, device=device),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_net = nn.Sequential(\n",
    "            nn.Linear(7*7*64, 300),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_net(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNet()\n",
    "model.load_state_dict(torch.load(\"MNIST_weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = CNN()\n",
    "model_cnn.load_state_dict(torch.load(\"MNIST_cnn_weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer_adam = torch.optim.Adam(model.parameters(), lr=1.8e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_cnn = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = torch.optim.Adam(model_cnn.parameters(), lr=2.5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, Y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Loss: {loss.item()}, batch: {batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, iteration):\n",
    "    num_batches = len(dataloader)\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X, Y) in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, Y)\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test {iteration+1} Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer_adam)\n",
    "    test_loop(test_dataloader, model, loss_fn, t)\n",
    "torch.save(model.state_dict(), \"MNIST_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00823370274156332, batch: 0\n",
      "Loss: 0.0548979751765728, batch: 100\n",
      "Loss: 0.019660314545035362, batch: 200\n",
      "Loss: 0.04747716709971428, batch: 300\n",
      "Loss: 0.06134342402219772, batch: 400\n",
      "Loss: 0.09203587472438812, batch: 500\n",
      "Loss: 0.038017965853214264, batch: 600\n",
      "Loss: 0.09057608246803284, batch: 700\n",
      "Loss: 0.1557389199733734, batch: 800\n",
      "Loss: 0.09154873341321945, batch: 900\n",
      "Test 1 Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.054713 \n",
      "\n",
      "Loss: 0.010318008251488209, batch: 0\n",
      "Loss: 0.058080460876226425, batch: 100\n",
      "Loss: 0.01949397474527359, batch: 200\n",
      "Loss: 0.011125986464321613, batch: 300\n",
      "Loss: 0.015666283667087555, batch: 400\n",
      "Loss: 0.09918995946645737, batch: 500\n",
      "Loss: 0.030022313818335533, batch: 600\n",
      "Loss: 0.025334451347589493, batch: 700\n",
      "Loss: 0.1753470003604889, batch: 800\n",
      "Loss: 0.03216719627380371, batch: 900\n",
      "Test 2 Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.053555 \n",
      "\n",
      "Loss: 0.0060417805798351765, batch: 0\n",
      "Loss: 0.009454065002501011, batch: 100\n",
      "Loss: 0.03304034844040871, batch: 200\n",
      "Loss: 0.027070768177509308, batch: 300\n",
      "Loss: 0.002161037875339389, batch: 400\n",
      "Loss: 0.004087392706423998, batch: 500\n",
      "Loss: 0.0007878515170887113, batch: 600\n",
      "Loss: 0.08623374253511429, batch: 700\n",
      "Loss: 0.09021291881799698, batch: 800\n",
      "Loss: 0.020614108070731163, batch: 900\n",
      "Test 3 Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.050063 \n",
      "\n",
      "Loss: 0.006683966610580683, batch: 0\n",
      "Loss: 0.028731869533658028, batch: 100\n",
      "Loss: 0.010953959077596664, batch: 200\n",
      "Loss: 0.0018524914048612118, batch: 300\n",
      "Loss: 0.0032366476953029633, batch: 400\n",
      "Loss: 0.0036762449890375137, batch: 500\n",
      "Loss: 0.005356393288820982, batch: 600\n",
      "Loss: 0.008952375501394272, batch: 700\n",
      "Loss: 0.0292116217315197, batch: 800\n",
      "Loss: 0.042096592485904694, batch: 900\n",
      "Test 4 Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.056223 \n",
      "\n",
      "Loss: 0.01026779692620039, batch: 0\n",
      "Loss: 0.03878110647201538, batch: 100\n",
      "Loss: 0.018626689910888672, batch: 200\n",
      "Loss: 0.013314695097506046, batch: 300\n",
      "Loss: 0.00873294286429882, batch: 400\n",
      "Loss: 0.03147779405117035, batch: 500\n",
      "Loss: 0.014405840076506138, batch: 600\n",
      "Loss: 0.004064915236085653, batch: 700\n",
      "Loss: 0.07117296010255814, batch: 800\n",
      "Loss: 0.011034864000976086, batch: 900\n",
      "Test 5 Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.043699 \n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "epochs2 = 1\n",
    "for t in range(epochs2):\n",
    "    train_loop(cnn_train_dataloader, model_cnn, loss_fn_cnn, optimizer_cnn)\n",
    "    test_loop(cnn_test_dataloader, model_cnn, loss_fn_cnn, t)\n",
    "print(\"DONE\")\n",
    "torch.save(model_cnn.state_dict(), \"MNIST_cnn_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
